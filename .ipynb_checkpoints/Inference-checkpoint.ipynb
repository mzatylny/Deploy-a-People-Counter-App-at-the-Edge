{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit persons to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging as log\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "\n",
    "class Network:\n",
    "    \"\"\"\n",
    "    Load and configure inference plugins for the specified target devices \n",
    "    and performs synchronous and asynchronous modes for the specified infer requests.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        ### TODO: Initialize any class variables desired ###\n",
    "        self.plugin = None # IEPlugin(device=\"CPU\")\n",
    "        self.network = None # IENetwork(model=path_to_xml_file=path_to_bin_file)\n",
    "        self.input_blob = None # next(iter(self.network.inputs))\n",
    "        self.output_blob = None # next(iter(self.network.outputs))\n",
    "        self.exec_network = None\n",
    "        self.infer_request = None\n",
    "        ##############################\n",
    "    \"\"\" self.ie = IECore()\n",
    "        self.net = IENetwork(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "        self.exec_net = ie.load_network(net, \"CPU\")\n",
    "        self.exec_net.get_metric(\"NETWORK_NAME\")\n",
    "    \"\"\" \n",
    "    def load_model(self, model, device, input_size, output_size, num_requests, extension=None, plugin=None):\n",
    "        \n",
    "        ### TODO: Load the model ###\n",
    "        model_xml = model\n",
    "        model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "        #####################################################################\n",
    "        #####################################################################\n",
    "        if not plugin:\n",
    "            log.info(\"Initializing IECore for {} device...\".format(device))\n",
    "            self.plugin = IECore(device=device)\n",
    "        else:\n",
    "            self.plugin = plugin\n",
    "\n",
    "        #self.plugin = IECore()\n",
    "\n",
    "        ###############################################################################\n",
    "        ### TODO: Check for supported layers ##########################################\n",
    "        if self.plugin.device == \"CPU\":\n",
    "            supported_layers = self.plugin.get_supported_layers(self.network)\n",
    "            not_supported_layers = \\\n",
    "                [l for l in self.network.layers.keys() if l not in supported_layers]\n",
    "            if len(not_supported_layers) != 0:\n",
    "                log.error(\"Following layers are not supported by \"\n",
    "                          \"the plugin for specified device {}:\\n {}\".\n",
    "                          format(self.plugin.device,\n",
    "                                 ', '.join(not_supported_layers)))\n",
    "                log.error(\"Please try to specify cpu extensions library path\"\n",
    "                          \" in command line parameters using -l \"\n",
    "                          \"or --cpu_extension command line argument\")\n",
    "                sys.exit(1)\n",
    "        ###############################################################################\n",
    "        ### TODO: Add any necessary extensions ########################################\n",
    "        if extension and \"CPU\" in device:\n",
    "            self.plugin.add_extension(extension, device)\n",
    "        ###############################################################################\n",
    "        \n",
    "        # Read the IR as a IENetwork\n",
    "        log.info(\"Reading IR...\")\n",
    "        \n",
    "        self.network = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "        log.info(\"Returning the loaded inference plugin...\")\n",
    "\n",
    "        ### TODO: Return the loaded inference plugin ###\n",
    "        # Load the IENetwork into the plugin\n",
    "        if num_requests == 0:\n",
    "            # Loads network read from IR to the plugin\n",
    "            self.exec_network = self.plugin.load(network=self.network)\n",
    "        else:\n",
    "            self.exec_network = self.plugin.load(network=self.network, num_requests=num_requests)\n",
    "        \n",
    "        # Get the input layer\n",
    "        self.input_blob = next(iter(self.network.inputs))\n",
    "        self.output_blob = next(iter(self.network.outputs))\n",
    "        ### Note: You may need to update the function parameters. ###\n",
    "        return self.plugin, self.get_input_shape()\n",
    "\n",
    "    def get_input_shape(self):\n",
    "        \n",
    "        ### TODO: Return the shape of the input layer ###\n",
    "        sh_imput = self.network.inputs[self.input_blob].shape\n",
    "\n",
    "        return sh_imput\n",
    "    \n",
    "\n",
    "    def exec_net(self, request_id, frame):\n",
    "        \n",
    "        ### TODO: Start an asynchronous request ###\n",
    "        ### TODO: Return any necessary information ###\n",
    "        ### Note: You may need to update the function parameters. ###\n",
    "        \n",
    "        self.infer_request = self.exec_network.start_async(\n",
    "            request_id=request_id, inputs={self.input_blob: frame})\n",
    "        return self.exec_network        \n",
    "\n",
    "    def wait(self,request_id):\n",
    "        ### TODO: Wait for the request to be complete. ###\n",
    "        ### TODO: Return any necessary information ###\n",
    "        ### Note: You may need to update the function parameters. ###\n",
    "        status = self.exec_network.requests[request_id].wait(-1)\n",
    "        return status\n",
    "    \n",
    "    def performance_counter(self, request_id):\n",
    "        \"\"\"\n",
    "        Queries performance measures per layer to get feedback of what is the\n",
    "        most time consuming layer.\n",
    "        :param request_id: Index of Infer request value. Limited to device capabilities\n",
    "        :return: Performance of the layer  \n",
    "        \"\"\"\n",
    "        perf_count = self.exec_network.requests[request_id].get_perf_counts()\n",
    "        return perf_count\n",
    "\n",
    "    def get_output(self, request_id, output=None):\n",
    "        ### TODO: Extract and return the output results\n",
    "        ### Note: You may need to update the function parameters. ###\n",
    "        if output:\n",
    "            out = self.infer_request.outputs[output]\n",
    "        else:\n",
    "            out = self.exec_network.requests[request_id].outputs[self.output_blob]\n",
    "        return out\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Deletes all the instances\n",
    "        :return: None\n",
    "        \"\"\" \n",
    "        del self.exec_network\n",
    "        del self.plugin\n",
    "        del self.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
